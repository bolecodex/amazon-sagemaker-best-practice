{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Amazon SageMaker Linear Learner algorithm for Taxi ride fare prediction\n",
    "_**Single machine training for regression with Amazon SageMaker Linear Learner algorithm**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This notebook demonstrates the use of Amazon SageMakerâ€™s implementation of the Linear Learner algorithm to train and host a regression model to predict taxi fare. This notebook uses the [New York City Taxi and Limousine Commission (TLC) Trip Record Data] (https://registry.opendata.aws/nyc-tlc-trip-records-pds/#) to train the model. We are not using the whole dataset from above but a small subset of the dataset to train our model here. You will download this subset of data in below steps.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup\n",
    "\n",
    "\n",
    "This notebook was tested in Amazon SageMaker Studio on a ml.t3.medium instance with Python 3 (Data Science) kernel.\n",
    "\n",
    "Let's start by specifying:\n",
    "1. The S3 buckets and prefixes that you want to use for training data and model data. This should be within the same region as the Notebook Instance, training, and hosting ( us-east-1).\n",
    "1. The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: numpy==1.19.5 in /opt/conda/lib/python3.7/site-packages (1.19.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/dhcrypto.py:16: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "/opt/conda/lib/python3.7/site-packages/secretstorage/util.py:25: CryptographyDeprecationWarning: int_from_bytes is deprecated, use int.from_bytes instead\n",
      "  from cryptography.utils import int_from_bytes\n",
      "Requirement already satisfied: pandas==0.25.3 in /opt/conda/lib/python3.7/site-packages (0.25.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.3) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# cell 01\n",
    "!pip install numpy==1.19.5\n",
    "!pip install pandas==0.25.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 02\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import sagemaker\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 03\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for training data.\n",
    "# this will create bucket like 'Sagemaker-<region>-<Your AccountId>'\n",
    "data_bucket=sess.default_bucket()\n",
    "data_prefix = \"1p-notebooks-datasets/taxi/text-csv\"\n",
    "\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "output_bucket = data_bucket\n",
    "output_prefix = \"sagemaker/DEMO-linear-learner-taxifare-regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before running the below cell make sure that you uploaded the nyc-taxi.csv file in Sagemaker Studio, provided to you, in the same folder where this Studio notebook is residing.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fare_amount vendor_id pickup_datetime dropoff_datetime  passenger_count  \\\n",
      "0         18.0       CMT   01/11/12 1:18    01/11/12 1:35                1   \n",
      "1         10.0       CMT   01/11/12 1:18    01/11/12 1:28                1   \n",
      "2         35.5       CMT   01/11/12 1:18    01/11/12 2:16                1   \n",
      "3          5.5       CMT   01/11/12 1:18    01/11/12 1:22                1   \n",
      "4         10.5       CMT   01/11/12 1:18    01/11/12 1:27                1   \n",
      "\n",
      "   trip_distance  pickup_longitude  pickup_latitude  rate_code  \\\n",
      "0            5.4        -73.984519        40.779776          1   \n",
      "1            2.4        -73.996082        40.753302          1   \n",
      "2            5.4        -73.970535        40.799144          1   \n",
      "3            1.1        -73.956560        40.771124          1   \n",
      "4            2.7        -73.959062        40.771722          1   \n",
      "\n",
      "  store_and_fwd_flag  dropoff_longitude  dropoff_latitude payment_type  \\\n",
      "0                  N         -73.947342         40.764681          CRD   \n",
      "1                  N         -73.985783         40.727865          CSH   \n",
      "2                  N         -73.957026         40.770164          CSH   \n",
      "3                  N         -73.960994         40.757343          CRD   \n",
      "4                  N         -73.967998         40.800170          CRD   \n",
      "\n",
      "   surcharge  mta_tax  tip_amount  tolls_amount  total_amount  \n",
      "0        0.5      0.5        3.80           0.0         22.80  \n",
      "1        0.5      0.5        0.00           0.0         11.00  \n",
      "2        0.5      0.5        0.00           0.0         36.50  \n",
      "3        0.5      0.5        1.62           0.0          8.12  \n",
      "4        0.5      0.5        2.85           0.0         14.35  \n"
     ]
    }
   ],
   "source": [
    "# cell 04\n",
    "import boto3\n",
    "FILE_TRAIN = \"nyc-taxi.csv\"\n",
    "# s3 = boto3.client(\"s3\")\n",
    "# s3.download_file(data_bucket, f\"{FILE_TRAIN}\", FILE_TRAIN)\n",
    "\n",
    "import pandas as pd  # Read in csv and store in a pandas dataframe\n",
    "\n",
    "# df = pd.read_csv(FILE_TRAIN, sep=\",\", encoding=\"latin1\")\n",
    "df = pd.read_csv(FILE_TRAIN, sep=\",\", encoding=\"latin1\", names=[\"fare_amount\",\"vendor_id\",\"pickup_datetime\",\"dropoff_datetime\",\"passenger_count\",\"trip_distance\",\"pickup_longitude\",\"pickup_latitude\",\"rate_code\",\"store_and_fwd_flag\",\"dropoff_longitude\",\"dropoff_latitude\",\"payment_type\",\"surcharge\",\"mta_tax\",\"tip_amount\",\"tolls_amount\",\"total_amount\"])\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24998 entries, 0 to 24997\n",
      "Data columns (total 18 columns):\n",
      "fare_amount           24998 non-null float64\n",
      "vendor_id             24998 non-null object\n",
      "pickup_datetime       24998 non-null object\n",
      "dropoff_datetime      24998 non-null object\n",
      "passenger_count       24998 non-null int64\n",
      "trip_distance         24998 non-null float64\n",
      "pickup_longitude      24998 non-null float64\n",
      "pickup_latitude       24998 non-null float64\n",
      "rate_code             24998 non-null int64\n",
      "store_and_fwd_flag    13789 non-null object\n",
      "dropoff_longitude     24998 non-null float64\n",
      "dropoff_latitude      24998 non-null float64\n",
      "payment_type          24998 non-null object\n",
      "surcharge             24998 non-null float64\n",
      "mta_tax               24998 non-null float64\n",
      "tip_amount            24998 non-null float64\n",
      "tolls_amount          24998 non-null float64\n",
      "total_amount          24998 non-null float64\n",
      "dtypes: float64(11), int64(2), object(5)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# cell 05\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have 18 features \"fare_amount\", \"vendor_id\", \"pickup_datetime\", \"dropoff_datetime\", \"passenger_count\", \"trip_distance\", \"pickup_longitude\", \"pickup_latitude\", \"rate_code\", \"store_and_fwd_flag\", \"dropoff_longitude\", \"dropoff_latitude\", \"payment_type\", \"surcharge\", \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"total_amount\" in the dataset\n",
    "\n",
    "Lets explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vendor_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CMT</th>\n",
       "      <td>0.551604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VTS</th>\n",
       "      <td>0.448396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0      % observations\n",
       "vendor_id                \n",
       "CMT              0.551604\n",
       "VTS              0.448396"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:34</th>\n",
       "      <td>0.00032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:35</th>\n",
       "      <td>0.00068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 10:22</th>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 1:18</th>\n",
       "      <td>0.00136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 1:19</th>\n",
       "      <td>0.00200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:04</th>\n",
       "      <td>0.00144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:05</th>\n",
       "      <td>0.00064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:31</th>\n",
       "      <td>0.00140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:32</th>\n",
       "      <td>0.00124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:33</th>\n",
       "      <td>0.00060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            % observations\n",
       "pickup_datetime                \n",
       "01/11/12 0:34           0.00032\n",
       "01/11/12 0:35           0.00068\n",
       "01/11/12 10:22          0.00052\n",
       "01/11/12 1:18           0.00136\n",
       "01/11/12 1:19           0.00200\n",
       "...                         ...\n",
       "03/11/12 9:04           0.00144\n",
       "03/11/12 9:05           0.00064\n",
       "03/11/12 9:31           0.00140\n",
       "03/11/12 9:32           0.00124\n",
       "03/11/12 9:33           0.00060\n",
       "\n",
       "[332 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:36</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:37</th>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:38</th>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:39</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/11/12 0:40</th>\n",
       "      <td>0.00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:49</th>\n",
       "      <td>0.00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:50</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:53</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:56</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03/11/12 9:58</th>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             % observations\n",
       "dropoff_datetime                \n",
       "01/11/12 0:36            0.00004\n",
       "01/11/12 0:37            0.00008\n",
       "01/11/12 0:38            0.00008\n",
       "01/11/12 0:39            0.00004\n",
       "01/11/12 0:40            0.00008\n",
       "...                          ...\n",
       "03/11/12 9:49            0.00020\n",
       "03/11/12 9:50            0.00004\n",
       "03/11/12 9:53            0.00004\n",
       "03/11/12 9:56            0.00004\n",
       "03/11/12 9:58            0.00004\n",
       "\n",
       "[864 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>0.980564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>0.019436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0               % observations\n",
       "store_and_fwd_flag                \n",
       "N                         0.980564\n",
       "Y                         0.019436"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>% observations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRD</th>\n",
       "      <td>0.441635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSH</th>\n",
       "      <td>0.554364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOC</th>\n",
       "      <td>0.002720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNK</th>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0         % observations\n",
       "payment_type                \n",
       "CRD                 0.441635\n",
       "CSH                 0.554364\n",
       "DIS                 0.001080\n",
       "NOC                 0.002720\n",
       "UNK                 0.000200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "      <td>24998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.351448</td>\n",
       "      <td>1.705496</td>\n",
       "      <td>3.273141</td>\n",
       "      <td>-72.571053</td>\n",
       "      <td>39.991996</td>\n",
       "      <td>1.040243</td>\n",
       "      <td>-72.525845</td>\n",
       "      <td>39.961398</td>\n",
       "      <td>0.364269</td>\n",
       "      <td>0.498200</td>\n",
       "      <td>1.098953</td>\n",
       "      <td>0.108989</td>\n",
       "      <td>14.421859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.221020</td>\n",
       "      <td>1.310985</td>\n",
       "      <td>3.541442</td>\n",
       "      <td>10.067793</td>\n",
       "      <td>5.518109</td>\n",
       "      <td>0.322975</td>\n",
       "      <td>10.223284</td>\n",
       "      <td>5.621274</td>\n",
       "      <td>0.223349</td>\n",
       "      <td>0.029948</td>\n",
       "      <td>1.949909</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>11.451719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-76.089603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-76.089573</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>-73.987745</td>\n",
       "      <td>40.743391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.988509</td>\n",
       "      <td>40.732185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>-73.975117</td>\n",
       "      <td>40.757236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.974993</td>\n",
       "      <td>40.755305</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.850000</td>\n",
       "      <td>-73.957477</td>\n",
       "      <td>40.771164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-73.954409</td>\n",
       "      <td>40.771601</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>41.043487</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>43.216667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>243.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  passenger_count  trip_distance  pickup_longitude  \\\n",
       "count  24998.000000     24998.000000   24998.000000      24998.000000   \n",
       "mean      12.351448         1.705496       3.273141        -72.571053   \n",
       "std       10.221020         1.310985       3.541442         10.067793   \n",
       "min        2.500000         1.000000       0.000000        -76.089603   \n",
       "25%        6.500000         1.000000       1.270000        -73.987745   \n",
       "50%        9.500000         1.000000       2.180000        -73.975117   \n",
       "75%       14.000000         2.000000       3.850000        -73.957477   \n",
       "max      243.000000         6.000000     100.000000          0.000000   \n",
       "\n",
       "       pickup_latitude     rate_code  dropoff_longitude  dropoff_latitude  \\\n",
       "count     24998.000000  24998.000000       24998.000000      24998.000000   \n",
       "mean         39.991996      1.040243         -72.525845         39.961398   \n",
       "std           5.518109      0.322975          10.223284          5.621274   \n",
       "min           0.000000      1.000000         -76.089573          0.000000   \n",
       "25%          40.743391      1.000000         -73.988509         40.732185   \n",
       "50%          40.757236      1.000000         -73.974993         40.755305   \n",
       "75%          40.771164      1.000000         -73.954409         40.771601   \n",
       "max          41.043487      5.000000           0.000000         43.216667   \n",
       "\n",
       "          surcharge       mta_tax    tip_amount  tolls_amount  total_amount  \n",
       "count  24998.000000  24998.000000  24998.000000  24998.000000  24998.000000  \n",
       "mean       0.364269      0.498200      1.098953      0.108989     14.421859  \n",
       "std        0.223349      0.029948      1.949909      0.777982     11.451719  \n",
       "min        0.000000      0.000000      0.000000      0.000000      3.000000  \n",
       "25%        0.000000      0.500000      0.000000      0.000000      8.000000  \n",
       "50%        0.500000      0.500000      0.000000      0.000000     11.000000  \n",
       "75%        0.500000      0.500000      1.700000      0.000000     16.500000  \n",
       "max        1.000000      0.500000     37.500000     17.900000    243.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cell 06\n",
    "# Frequency tables for each categorical feature\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    display(pd.crosstab(index=df[column], columns='% observations', normalize='columns'))\n",
    "\n",
    "# Histograms for each numeric features\n",
    "display(df.describe())\n",
    "%matplotlib inline\n",
    "hist = df.hist(bins=30, sharey=True, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see that store_and_fwd_flg column doesn't have much variance in it ( as 98% of the column values are N and 2% are Y) hence this column won't have much impact on target variable ( fare_amount ). Also from our domain knowledge we can see that payment_type column value doesn't impact on trip fare hence we can drop both of these features from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24998 entries, 0 to 24997\n",
      "Data columns (total 16 columns):\n",
      "fare_amount          24998 non-null float64\n",
      "vendor_id            24998 non-null object\n",
      "pickup_datetime      24998 non-null object\n",
      "dropoff_datetime     24998 non-null object\n",
      "passenger_count      24998 non-null int64\n",
      "trip_distance        24998 non-null float64\n",
      "pickup_longitude     24998 non-null float64\n",
      "pickup_latitude      24998 non-null float64\n",
      "rate_code            24998 non-null int64\n",
      "dropoff_longitude    24998 non-null float64\n",
      "dropoff_latitude     24998 non-null float64\n",
      "surcharge            24998 non-null float64\n",
      "mta_tax              24998 non-null float64\n",
      "tip_amount           24998 non-null float64\n",
      "tolls_amount         24998 non-null float64\n",
      "total_amount         24998 non-null float64\n",
      "dtypes: float64(11), int64(2), object(3)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# cell 07\n",
    "df = df.drop(['payment_type', 'store_and_fwd_flag'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that in the dataset there are 2 features 'pickup_datetime' and 'dropoff_datetime' which depict when ride started and when did it end. As we know that taxi fare is highly dependent on duration of the drive hence as part of feature engineering we will create a feature which will calculate ride duration using these  features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1020.0\n",
       "1         600.0\n",
       "2        3480.0\n",
       "3         240.0\n",
       "4         540.0\n",
       "          ...  \n",
       "24993     540.0\n",
       "24994     420.0\n",
       "24995     600.0\n",
       "24996    1200.0\n",
       "24997     420.0\n",
       "Name: journey_time, Length: 24998, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell 08\n",
    "df['dropoff_datetime']= pd.to_datetime(df['dropoff_datetime'])\n",
    "df['pickup_datetime']= pd.to_datetime(df['pickup_datetime'])\n",
    "df['journey_time'] = (df['dropoff_datetime'] - df['pickup_datetime'])\n",
    "df['journey_time'] = df['journey_time'].dt.total_seconds()\n",
    "df['journey_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### after creation of 'journey_time feature' we can drop 'pickup_datetime' and 'dropoff_datetime' features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24998 entries, 0 to 24997\n",
      "Data columns (total 15 columns):\n",
      "fare_amount          24998 non-null float64\n",
      "vendor_id            24998 non-null object\n",
      "passenger_count      24998 non-null int64\n",
      "trip_distance        24998 non-null float64\n",
      "pickup_longitude     24998 non-null float64\n",
      "pickup_latitude      24998 non-null float64\n",
      "rate_code            24998 non-null int64\n",
      "dropoff_longitude    24998 non-null float64\n",
      "dropoff_latitude     24998 non-null float64\n",
      "surcharge            24998 non-null float64\n",
      "mta_tax              24998 non-null float64\n",
      "tip_amount           24998 non-null float64\n",
      "tolls_amount         24998 non-null float64\n",
      "total_amount         24998 non-null float64\n",
      "journey_time         24998 non-null float64\n",
      "dtypes: float64(12), int64(2), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# cell 09\n",
    "df = df.drop(['dropoff_datetime', 'pickup_datetime'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As you can see that vedor_id is still a categorical feature and we need to chage it to float ( using dummuies 0) so that dataset can be passed to Liner learner algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24998 entries, 0 to 24997\n",
      "Data columns (total 16 columns):\n",
      "fare_amount          24998 non-null float64\n",
      "passenger_count      24998 non-null int64\n",
      "trip_distance        24998 non-null float64\n",
      "pickup_longitude     24998 non-null float64\n",
      "pickup_latitude      24998 non-null float64\n",
      "rate_code            24998 non-null int64\n",
      "dropoff_longitude    24998 non-null float64\n",
      "dropoff_latitude     24998 non-null float64\n",
      "surcharge            24998 non-null float64\n",
      "mta_tax              24998 non-null float64\n",
      "tip_amount           24998 non-null float64\n",
      "tolls_amount         24998 non-null float64\n",
      "total_amount         24998 non-null float64\n",
      "journey_time         24998 non-null float64\n",
      "vendor_id_CMT        24998 non-null float64\n",
      "vendor_id_VTS        24998 non-null float64\n",
      "dtypes: float64(14), int64(2)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# cell 10\n",
    "df = pd.get_dummies(df, dtype=float)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataframe in train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 11\n",
    "import numpy as np\n",
    "\n",
    "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len(df)), int(0.9 * len(df))])\n",
    "train_data.to_csv('train.csv', header=False, index=False)\n",
    "validation_data.to_csv('validation.csv', header=False, index=False)\n",
    "test_data.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 12\n",
    "boto3.Session().resource('s3').Bucket(data_bucket).Object(os.path.join(data_prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "boto3.Session().resource('s3').Bucket(data_bucket).Object(os.path.join(data_prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
    "boto3.Session().resource('s3').Bucket(data_bucket).Object(os.path.join(data_prefix, 'test/test.csv')).upload_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "Let us prepare the handshake between our data channels and the algorithm. To do this, we need to create the `sagemaker.session.s3_input` objects from our [data channels](https://sagemaker.readthedocs.io/en/v1.2.4/session.html#). These objects are then put in a simple dictionary, which the algorithm consumes. Notice that here we use a `content_type` as `text/csv` for the pre-processed file in the data_bucket. We use two channels here one for training and the second one for validation. The testing samples from above will be used on the prediction step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training files will be taken from: s3://sagemaker-us-east-1-071908484098/1p-notebooks-datasets/taxi/text-csv/train\n",
      "validtion files will be taken from: s3://sagemaker-us-east-1-071908484098/1p-notebooks-datasets/taxi/text-csv/validation\n",
      "test files will be taken from: s3://sagemaker-us-east-1-071908484098/1p-notebooks-datasets/taxi/text-csv/test\n",
      "training artifacts output location: s3://sagemaker-us-east-1-071908484098/sagemaker/DEMO-linear-learner-taxifare-regression/output\n"
     ]
    }
   ],
   "source": [
    "# cell 13\n",
    "# creating the inputs for the fit() function with the training and validation location\n",
    "s3_train_data = f\"s3://{data_bucket}/{data_prefix}/train\"\n",
    "print(f\"training files will be taken from: {s3_train_data}\")\n",
    "\n",
    "s3_validation_data = f\"s3://{data_bucket}/{data_prefix}/validation\"\n",
    "print(f\"validtion files will be taken from: {s3_validation_data}\")\n",
    "\n",
    "s3_test_data = f\"s3://{data_bucket}/{data_prefix}/test\"\n",
    "print(f\"test files will be taken from: {s3_test_data}\")\n",
    "\n",
    "output_location = f\"s3://{output_bucket}/{output_prefix}/output\"\n",
    "print(f\"training artifacts output location: {output_location}\")\n",
    "\n",
    "# generating the session.s3_input() format for fit() accepted by the sdk\n",
    "train_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_train_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")\n",
    "validation_data = sagemaker.inputs.TrainingInput(\n",
    "    s3_validation_data,\n",
    "    distribution=\"FullyReplicated\",\n",
    "    content_type=\"text/csv\",\n",
    "    s3_data_type=\"S3Prefix\",\n",
    "    record_wrapping=None,\n",
    "    compression=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Linear Learner model\n",
    "\n",
    "First, we retrieve the image for the Linear Learner Algorithm according to the region.\n",
    "\n",
    "Then we create an [estimator from the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) using the Linear Learner container image and we setup the training parameters and hyperparameters configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382416733822.dkr.ecr.us-east-1.amazonaws.com/linear-learner:1\n"
     ]
    }
   ],
   "source": [
    "# cell 14\n",
    "# getting the linear learner image according to the region\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "container = retrieve(\"linear-learner\", boto3.Session().region_name, version=\"1\")\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training job DEMO-linear-learner-taxifare-regression-21-16-46\n"
     ]
    }
   ],
   "source": [
    "# cell 15\n",
    "# %%time\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "job_name = \"DEMO-linear-learner-taxifare-regression-\" + strftime(\"%H-%M-%S\", gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    input_mode=\"File\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "linear.set_hyperparameters(\n",
    "    epochs=16,\n",
    "    wd=0.01,\n",
    "    loss=\"absolute_loss\",\n",
    "    predictor_type=\"regressor\",\n",
    "    normalize_data=True,\n",
    "    optimizer=\"adam\",\n",
    "    mini_batch_size=1000,\n",
    "    lr_scheduler_step=100,\n",
    "    lr_scheduler_factor=0.99,\n",
    "    lr_scheduler_minimum_lr=0.0001,\n",
    "    learning_rate=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "After configuring the Estimator object and setting the hyperparameters for this object. The only remaining thing to do is to train the algorithm. The following cell will train the algorithm. Training the algorithm involves a few steps. Firstly, the instances that we requested while creating the Estimator classes are provisioned and are setup with the appropriate libraries. Then, the data from our channels are downloaded into the instance. Once this is done, the training job begins. The provisioning and data downloading will take time, depending on the size of the data. Therefore it might be a few minutes before we start getting data logs for our training jobs. The data logs will also print out Mean Average Precision (mAP) on the validation data, among other losses, for every run of the dataset once or one epoch. This metric is a proxy for the quality of the algorithm.\n",
    "\n",
    "Once the job has finished a \"Job complete\" message will be printed. The trained model can be found in the S3 bucket that was setup as output_path in the estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-23 21:17:13 Starting - Starting the training job...ProfilerReport-1648070233: InProgress\n",
      "...\n",
      "2022-03-23 21:18:11 Starting - Preparing the instances for training.........\n",
      "2022-03-23 21:19:31 Downloading - Downloading input data...\n",
      "2022-03-23 21:20:11 Training - Downloading the training image...\n",
      "2022-03-23 21:20:42 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328 integration.py:636] worker started\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '16', 'learning_rate': '0.1', 'loss': 'absolute_loss', 'lr_scheduler_factor': '0.99', 'lr_scheduler_minimum_lr': '0.0001', 'lr_scheduler_step': '100', 'mini_batch_size': '1000', 'normalize_data': 'True', 'optimizer': 'adam', 'predictor_type': 'regressor', 'wd': '0.01'}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Final configuration: {'mini_batch_size': '1000', 'epochs': '16', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'adam', 'loss': 'absolute_loss', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': '0.01', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': '0.1', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': '100', 'lr_scheduler_factor': '0.99', 'lr_scheduler_minimum_lr': '0.0001', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'True', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'regressor'}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 WARNING 139682313451328] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Using default worker.\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Create Store: local\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f09f2669290>\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Scaling model computed with parameters:\n",
      " {'stdev_label': \u001b[0m\n",
      "\u001b[34m[10.6103325]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.3070091e+00 3.5066948e+00 1.0515575e+01 5.7811842e+00 3.1933939e-01\n",
      " 1.0605734e+01 5.8308725e+00 2.2492871e-01 2.8557034e-02 1.9322473e+00\n",
      " 7.1918929e-01 1.1728467e+01 2.0943656e+05 4.9696580e-01 4.9696580e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 15 @cpu(0)>, 'mean_label': \u001b[0m\n",
      "\u001b[34m[12.458818]\u001b[0m\n",
      "\u001b[34m<NDArray 1 @cpu(0)>, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[ 1.7095456e+00  3.2892518e+00 -7.2441216e+01  3.9915714e+01\n",
      "  1.0407274e+00 -7.2412895e+01  3.9899578e+01  3.6159089e-01\n",
      "  4.9836370e-01  1.0816537e+00  9.5663652e-02  1.4496091e+01\n",
      "  1.8879422e+04  5.5500013e-01  4.4500005e-01]\u001b[0m\n",
      "\u001b[34m<NDArray 15 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] nvidia-smi: took 0.033 seconds to run.\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:49 INFO 139682313451328] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070449.9232135, \"EndTime\": 1648070449.923256, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 12000.0, \"count\": 1, \"min\": 12000, \"max\": 12000}, \"Total Batches Seen\": {\"sum\": 12.0, \"count\": 1, \"min\": 12, \"max\": 12}, \"Max Records Seen Between Resets\": {\"sum\": 11000.0, \"count\": 1, \"min\": 11000, \"max\": 11000}, \"Max Batches Seen Between Resets\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5553944, \"EndTime\": 1648070450.5555205, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36113863417681524, \"count\": 1, \"min\": 0.36113863417681524, \"max\": 0.36113863417681524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.555677, \"EndTime\": 1648070450.5557048, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4953607105928309, \"count\": 1, \"min\": 0.4953607105928309, \"max\": 0.4953607105928309}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.555788, \"EndTime\": 1648070450.5558069, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5418412673052619, \"count\": 1, \"min\": 0.5418412673052619, \"max\": 0.5418412673052619}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5558667, \"EndTime\": 1648070450.555885, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.46846175967945775, \"count\": 1, \"min\": 0.46846175967945775, \"max\": 0.46846175967945775}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.555942, \"EndTime\": 1648070450.5559604, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3748058256261489, \"count\": 1, \"min\": 0.3748058256261489, \"max\": 0.3748058256261489}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5560133, \"EndTime\": 1648070450.5560372, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38292065025778377, \"count\": 1, \"min\": 0.38292065025778377, \"max\": 0.38292065025778377}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5560932, \"EndTime\": 1648070450.5561109, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3690360035615809, \"count\": 1, \"min\": 0.3690360035615809, \"max\": 0.3690360035615809}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5561712, \"EndTime\": 1648070450.5561874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3700210553337546, \"count\": 1, \"min\": 0.3700210553337546, \"max\": 0.3700210553337546}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5562468, \"EndTime\": 1648070450.556263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5261142847397748, \"count\": 1, \"min\": 0.5261142847397748, \"max\": 0.5261142847397748}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5563161, \"EndTime\": 1648070450.5563312, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5785899442784926, \"count\": 1, \"min\": 0.5785899442784926, \"max\": 0.5785899442784926}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5563784, \"EndTime\": 1648070450.5563927, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4339815207088695, \"count\": 1, \"min\": 0.4339815207088695, \"max\": 0.4339815207088695}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.55644, \"EndTime\": 1648070450.5564544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.47184315759995404, \"count\": 1, \"min\": 0.47184315759995404, \"max\": 0.47184315759995404}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5565214, \"EndTime\": 1648070450.5565383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3512503294103286, \"count\": 1, \"min\": 0.3512503294103286, \"max\": 0.3512503294103286}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.556593, \"EndTime\": 1648070450.5566118, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4013652675853056, \"count\": 1, \"min\": 0.4013652675853056, \"max\": 0.4013652675853056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5566642, \"EndTime\": 1648070450.5566812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3712298745548024, \"count\": 1, \"min\": 0.3712298745548024, \"max\": 0.3712298745548024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5567381, \"EndTime\": 1648070450.5568445, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.38263309703153725, \"count\": 1, \"min\": 0.38263309703153725, \"max\": 0.38263309703153725}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5569158, \"EndTime\": 1648070450.556935, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5532775089039522, \"count\": 1, \"min\": 0.5532775089039522, \"max\": 0.5532775089039522}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5569866, \"EndTime\": 1648070450.5570047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.49477485746495864, \"count\": 1, \"min\": 0.49477485746495864, \"max\": 0.49477485746495864}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.557059, \"EndTime\": 1648070450.557087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4675099182128906, \"count\": 1, \"min\": 0.4675099182128906, \"max\": 0.4675099182128906}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.557142, \"EndTime\": 1648070450.557158, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4895863198673024, \"count\": 1, \"min\": 0.4895863198673024, \"max\": 0.4895863198673024}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5572047, \"EndTime\": 1648070450.557219, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3987579974006204, \"count\": 1, \"min\": 0.3987579974006204, \"max\": 0.3987579974006204}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5572712, \"EndTime\": 1648070450.5572891, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36399925231933594, \"count\": 1, \"min\": 0.36399925231933594, \"max\": 0.36399925231933594}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.557344, \"EndTime\": 1648070450.5573614, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.360065403657801, \"count\": 1, \"min\": 0.360065403657801, \"max\": 0.360065403657801}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.557413, \"EndTime\": 1648070450.5574293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39358737003102023, \"count\": 1, \"min\": 0.39358737003102023, \"max\": 0.39358737003102023}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5574841, \"EndTime\": 1648070450.5575023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5650297456629136, \"count\": 1, \"min\": 0.5650297456629136, \"max\": 0.5650297456629136}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5575614, \"EndTime\": 1648070450.5575807, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5788284876206342, \"count\": 1, \"min\": 0.5788284876206342, \"max\": 0.5788284876206342}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5576365, \"EndTime\": 1648070450.557651, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.57731641702091, \"count\": 1, \"min\": 0.57731641702091, \"max\": 0.57731641702091}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5577009, \"EndTime\": 1648070450.5577176, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5495467690860524, \"count\": 1, \"min\": 0.5495467690860524, \"max\": 0.5495467690860524}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.557767, \"EndTime\": 1648070450.5577834, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6087828063964844, \"count\": 1, \"min\": 0.6087828063964844, \"max\": 0.6087828063964844}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5578408, \"EndTime\": 1648070450.5578575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6420302375344669, \"count\": 1, \"min\": 0.6420302375344669, \"max\": 0.6420302375344669}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5579095, \"EndTime\": 1648070450.557926, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6407510842715992, \"count\": 1, \"min\": 0.6407510842715992, \"max\": 0.6407510842715992}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.5579762, \"EndTime\": 1648070450.5579925, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.6392654777975644, \"count\": 1, \"min\": 0.6392654777975644, \"max\": 0.6392654777975644}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] #quality_metric: host=algo-1, epoch=0, train absolute_loss_objective <loss>=0.36113863417681524\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.737039, \"EndTime\": 1648070450.7372267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.662186962890625, \"count\": 1, \"min\": 1.662186962890625, \"max\": 1.662186962890625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.73737, \"EndTime\": 1648070450.7373958, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.157698291015625, \"count\": 1, \"min\": 4.157698291015625, \"max\": 4.157698291015625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.737448, \"EndTime\": 1648070450.7374635, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.61016669921875, \"count\": 1, \"min\": 4.61016669921875, \"max\": 4.61016669921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.737512, \"EndTime\": 1648070450.7375271, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.917664794921875, \"count\": 1, \"min\": 3.917664794921875, \"max\": 3.917664794921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7375731, \"EndTime\": 1648070450.7375882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.780623828125, \"count\": 1, \"min\": 1.780623828125, \"max\": 1.780623828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7376392, \"EndTime\": 1648070450.7376564, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.0135412109375, \"count\": 1, \"min\": 2.0135412109375, \"max\": 2.0135412109375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7377052, \"EndTime\": 1648070450.7377195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.6099715576171876, \"count\": 1, \"min\": 1.6099715576171876, \"max\": 1.6099715576171876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7377634, \"EndTime\": 1648070450.7379663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.789517333984375, \"count\": 1, \"min\": 1.789517333984375, \"max\": 1.789517333984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7380338, \"EndTime\": 1648070450.7380528, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.46341142578125, \"count\": 1, \"min\": 4.46341142578125, \"max\": 4.46341142578125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7382479, \"EndTime\": 1648070450.7382681, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.9568072265625, \"count\": 1, \"min\": 4.9568072265625, \"max\": 4.9568072265625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7384503, \"EndTime\": 1648070450.7384741, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.63690205078125, \"count\": 1, \"min\": 3.63690205078125, \"max\": 3.63690205078125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7386067, \"EndTime\": 1648070450.738629, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.014024169921875, \"count\": 1, \"min\": 4.014024169921875, \"max\": 4.014024169921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7386887, \"EndTime\": 1648070450.738786, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.4689070556640624, \"count\": 1, \"min\": 1.4689070556640624, \"max\": 1.4689070556640624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7389176, \"EndTime\": 1648070450.738942, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.52108232421875, \"count\": 1, \"min\": 2.52108232421875, \"max\": 2.52108232421875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7390802, \"EndTime\": 1648070450.7391024, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.351964794921875, \"count\": 1, \"min\": 2.351964794921875, \"max\": 2.351964794921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7392602, \"EndTime\": 1648070450.7392802, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.8942760498046876, \"count\": 1, \"min\": 1.8942760498046876, \"max\": 1.8942760498046876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7393312, \"EndTime\": 1648070450.739346, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.747725390625, \"count\": 1, \"min\": 4.747725390625, \"max\": 4.747725390625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7395647, \"EndTime\": 1648070450.739589, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.260128125, \"count\": 1, \"min\": 4.260128125, \"max\": 4.260128125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.739645, \"EndTime\": 1648070450.7397468, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.997765673828125, \"count\": 1, \"min\": 3.997765673828125, \"max\": 3.997765673828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7398949, \"EndTime\": 1648070450.7399163, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 4.105459326171875, \"count\": 1, \"min\": 4.105459326171875, \"max\": 4.105459326171875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7399755, \"EndTime\": 1648070450.7400715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.54783232421875, \"count\": 1, \"min\": 2.54783232421875, \"max\": 2.54783232421875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.740222, \"EndTime\": 1648070450.7402506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.73824462890625, \"count\": 1, \"min\": 2.73824462890625, \"max\": 2.73824462890625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.740406, \"EndTime\": 1648070450.7404299, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.605124462890625, \"count\": 1, \"min\": 2.605124462890625, \"max\": 2.605124462890625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7404916, \"EndTime\": 1648070450.74051, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.46235888671875, \"count\": 1, \"min\": 2.46235888671875, \"max\": 2.46235888671875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7405655, \"EndTime\": 1648070450.7405832, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.528740625, \"count\": 1, \"min\": 5.528740625, \"max\": 5.528740625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7406366, \"EndTime\": 1648070450.740652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.439909375, \"count\": 1, \"min\": 5.439909375, \"max\": 5.439909375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7408848, \"EndTime\": 1648070450.7409065, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.487525390625, \"count\": 1, \"min\": 5.487525390625, \"max\": 5.487525390625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7410529, \"EndTime\": 1648070450.7411592, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.6837927734375, \"count\": 1, \"min\": 5.6837927734375, \"max\": 5.6837927734375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7412298, \"EndTime\": 1648070450.7412486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.78493134765625, \"count\": 1, \"min\": 5.78493134765625, \"max\": 5.78493134765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7413054, \"EndTime\": 1648070450.741322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.78302353515625, \"count\": 1, \"min\": 5.78302353515625, \"max\": 5.78302353515625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7413738, \"EndTime\": 1648070450.7413888, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.88792412109375, \"count\": 1, \"min\": 5.88792412109375, \"max\": 5.88792412109375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.7414455, \"EndTime\": 1648070450.7414677, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.73386728515625, \"count\": 1, \"min\": 5.73386728515625, \"max\": 5.73386728515625}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] #quality_metric: host=algo-1, epoch=0, validation absolute_loss_objective <loss>=1.662186962890625\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=absolute_loss_objective, value=1.4689070556640624\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] Saved checkpoint to \"/tmp/tmpv2k7hr2r/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] #progress_metric: host=algo-1, completed 6.25 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070449.9236186, \"EndTime\": 1648070450.7569077, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 29498.0, \"count\": 1, \"min\": 29498, \"max\": 29498}, \"Total Batches Seen\": {\"sum\": 30.0, \"count\": 1, \"min\": 30, \"max\": 30}, \"Max Records Seen Between Resets\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Max Batches Seen Between Resets\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Number of Batches Since Last Reset\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:50 INFO 139682313451328] #throughput_metric: host=algo-1, train throughput=20989.92126827382 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4944148, \"EndTime\": 1648070451.4944882, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11402796621883617, \"count\": 1, \"min\": 0.11402796621883617, \"max\": 0.11402796621883617}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4945805, \"EndTime\": 1648070451.4945943, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35958431827320775, \"count\": 1, \"min\": 0.35958431827320775, \"max\": 0.35958431827320775}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.494635, \"EndTime\": 1648070451.4946506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.40265861960018384, \"count\": 1, \"min\": 0.40265861960018384, \"max\": 0.40265861960018384}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4947062, \"EndTime\": 1648070451.4947224, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.33471733901079964, \"count\": 1, \"min\": 0.33471733901079964, \"max\": 0.33471733901079964}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.494784, \"EndTime\": 1648070451.4948018, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13498261620016658, \"count\": 1, \"min\": 0.13498261620016658, \"max\": 0.13498261620016658}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4948642, \"EndTime\": 1648070451.4948792, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1278264496747185, \"count\": 1, \"min\": 0.1278264496747185, \"max\": 0.1278264496747185}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.494926, \"EndTime\": 1648070451.4949408, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.10793425526338465, \"count\": 1, \"min\": 0.10793425526338465, \"max\": 0.10793425526338465}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4949856, \"EndTime\": 1648070451.4949996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13256121197868795, \"count\": 1, \"min\": 0.13256121197868795, \"max\": 0.13256121197868795}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.495044, \"EndTime\": 1648070451.495057, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.39147532564051013, \"count\": 1, \"min\": 0.39147532564051013, \"max\": 0.39147532564051013}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4951053, \"EndTime\": 1648070451.4951212, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.43347521613625917, \"count\": 1, \"min\": 0.43347521613625917, \"max\": 0.43347521613625917}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4951737, \"EndTime\": 1648070451.4951913, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.313895897360409, \"count\": 1, \"min\": 0.313895897360409, \"max\": 0.313895897360409}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4952369, \"EndTime\": 1648070451.4952524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3564782319910386, \"count\": 1, \"min\": 0.3564782319910386, \"max\": 0.3564782319910386}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4953048, \"EndTime\": 1648070451.4953208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11643587538775275, \"count\": 1, \"min\": 0.11643587538775275, \"max\": 0.11643587538775275}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4953728, \"EndTime\": 1648070451.4953895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1534874590705423, \"count\": 1, \"min\": 0.1534874590705423, \"max\": 0.1534874590705423}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4954398, \"EndTime\": 1648070451.4954557, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.14860651397705077, \"count\": 1, \"min\": 0.14860651397705077, \"max\": 0.14860651397705077}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4955058, \"EndTime\": 1648070451.4955215, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.135654759126551, \"count\": 1, \"min\": 0.135654759126551, \"max\": 0.135654759126551}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4955745, \"EndTime\": 1648070451.495591, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.4211196719898897, \"count\": 1, \"min\": 0.4211196719898897, \"max\": 0.4211196719898897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4956417, \"EndTime\": 1648070451.4956572, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3794910224465763, \"count\": 1, \"min\": 0.3794910224465763, \"max\": 0.3794910224465763}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4957118, \"EndTime\": 1648070451.4957273, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.35183292703067554, \"count\": 1, \"min\": 0.35183292703067554, \"max\": 0.35183292703067554}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4957786, \"EndTime\": 1648070451.4957945, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.36060266292796417, \"count\": 1, \"min\": 0.36060266292796417, \"max\": 0.36060266292796417}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4958441, \"EndTime\": 1648070451.4958603, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1973949759988224, \"count\": 1, \"min\": 0.1973949759988224, \"max\": 0.1973949759988224}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4959142, \"EndTime\": 1648070451.4959302, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17700425854851218, \"count\": 1, \"min\": 0.17700425854851218, \"max\": 0.17700425854851218}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4959846, \"EndTime\": 1648070451.4960017, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.17611054499009077, \"count\": 1, \"min\": 0.17611054499009077, \"max\": 0.17611054499009077}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496057, \"EndTime\": 1648070451.4960737, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.20058974770938648, \"count\": 1, \"min\": 0.20058974770938648, \"max\": 0.20058974770938648}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496126, \"EndTime\": 1648070451.496143, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5528786800608916, \"count\": 1, \"min\": 0.5528786800608916, \"max\": 0.5528786800608916}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496198, \"EndTime\": 1648070451.4962149, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5488127692727481, \"count\": 1, \"min\": 0.5488127692727481, \"max\": 0.5488127692727481}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496268, \"EndTime\": 1648070451.4962835, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5486333438648897, \"count\": 1, \"min\": 0.5486333438648897, \"max\": 0.5486333438648897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4963348, \"EndTime\": 1648070451.4963515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5596135218003216, \"count\": 1, \"min\": 0.5596135218003216, \"max\": 0.5596135218003216}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4964025, \"EndTime\": 1648070451.4964185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5572790276022518, \"count\": 1, \"min\": 0.5572790276022518, \"max\": 0.5572790276022518}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496469, \"EndTime\": 1648070451.496486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5600958862304688, \"count\": 1, \"min\": 0.5600958862304688, \"max\": 0.5600958862304688}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.496537, \"EndTime\": 1648070451.496555, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5640369549919577, \"count\": 1, \"min\": 0.5640369549919577, \"max\": 0.5640369549919577}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.4966052, \"EndTime\": 1648070451.4966207, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5617008379767923, \"count\": 1, \"min\": 0.5617008379767923, \"max\": 0.5617008379767923}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] #quality_metric: host=algo-1, epoch=1, train absolute_loss_objective <loss>=0.11402796621883617\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6937103, \"EndTime\": 1648070451.6938665, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.8457241333007812, \"count\": 1, \"min\": 0.8457241333007812, \"max\": 0.8457241333007812}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6940267, \"EndTime\": 1648070451.6940506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.11748173828125, \"count\": 1, \"min\": 3.11748173828125, \"max\": 3.11748173828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6941235, \"EndTime\": 1648070451.6941419, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.49285048828125, \"count\": 1, \"min\": 3.49285048828125, \"max\": 3.49285048828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6941977, \"EndTime\": 1648070451.6942139, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.85618017578125, \"count\": 1, \"min\": 2.85618017578125, \"max\": 2.85618017578125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.694267, \"EndTime\": 1648070451.6942844, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.7494934814453125, \"count\": 1, \"min\": 0.7494934814453125, \"max\": 0.7494934814453125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.694344, \"EndTime\": 1648070451.694361, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.843162060546875, \"count\": 1, \"min\": 0.843162060546875, \"max\": 0.843162060546875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.694414, \"EndTime\": 1648070451.6944284, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.8296254760742188, \"count\": 1, \"min\": 0.8296254760742188, \"max\": 0.8296254760742188}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.694474, \"EndTime\": 1648070451.6944897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.6742811401367188, \"count\": 1, \"min\": 0.6742811401367188, \"max\": 0.6742811401367188}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6945426, \"EndTime\": 1648070451.6945581, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.430368994140625, \"count\": 1, \"min\": 3.430368994140625, \"max\": 3.430368994140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6946099, \"EndTime\": 1648070451.6946263, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.765533056640625, \"count\": 1, \"min\": 3.765533056640625, \"max\": 3.765533056640625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6946764, \"EndTime\": 1648070451.694693, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.740255029296875, \"count\": 1, \"min\": 2.740255029296875, \"max\": 2.740255029296875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6947436, \"EndTime\": 1648070451.694759, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.2054419921875, \"count\": 1, \"min\": 3.2054419921875, \"max\": 3.2054419921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6948066, \"EndTime\": 1648070451.6948206, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.8540639892578125, \"count\": 1, \"min\": 0.8540639892578125, \"max\": 0.8540639892578125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6948724, \"EndTime\": 1648070451.694888, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.20416640625, \"count\": 1, \"min\": 1.20416640625, \"max\": 1.20416640625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6949422, \"EndTime\": 1648070451.6949584, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.3007739990234375, \"count\": 1, \"min\": 1.3007739990234375, \"max\": 1.3007739990234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6950119, \"EndTime\": 1648070451.695028, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.9220379638671875, \"count\": 1, \"min\": 0.9220379638671875, \"max\": 0.9220379638671875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695076, \"EndTime\": 1648070451.6950896, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.7006935546875, \"count\": 1, \"min\": 3.7006935546875, \"max\": 3.7006935546875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6951358, \"EndTime\": 1648070451.6951513, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.36485888671875, \"count\": 1, \"min\": 3.36485888671875, \"max\": 3.36485888671875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6951976, \"EndTime\": 1648070451.6952112, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.091339599609375, \"count\": 1, \"min\": 3.091339599609375, \"max\": 3.091339599609375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6952596, \"EndTime\": 1648070451.6952753, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.139783251953125, \"count\": 1, \"min\": 3.139783251953125, \"max\": 3.139783251953125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695321, \"EndTime\": 1648070451.6953344, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.2801742919921875, \"count\": 1, \"min\": 1.2801742919921875, \"max\": 1.2801742919921875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6953804, \"EndTime\": 1648070451.6953952, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.3917083984375, \"count\": 1, \"min\": 1.3917083984375, \"max\": 1.3917083984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695442, \"EndTime\": 1648070451.695456, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.446954296875, \"count\": 1, \"min\": 1.446954296875, \"max\": 1.446954296875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6955009, \"EndTime\": 1648070451.695515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.4708493408203125, \"count\": 1, \"min\": 1.4708493408203125, \"max\": 1.4708493408203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695567, \"EndTime\": 1648070451.6955888, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.54116748046875, \"count\": 1, \"min\": 5.54116748046875, \"max\": 5.54116748046875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695636, \"EndTime\": 1648070451.6956499, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.57100634765625, \"count\": 1, \"min\": 5.57100634765625, \"max\": 5.57100634765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695696, \"EndTime\": 1648070451.6957114, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.56472783203125, \"count\": 1, \"min\": 5.56472783203125, \"max\": 5.56472783203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6957624, \"EndTime\": 1648070451.6957793, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.54545908203125, \"count\": 1, \"min\": 5.54545908203125, \"max\": 5.54545908203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.69584, \"EndTime\": 1648070451.69586, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5644478515625, \"count\": 1, \"min\": 5.5644478515625, \"max\": 5.5644478515625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.695913, \"EndTime\": 1648070451.6959293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5990462890625, \"count\": 1, \"min\": 5.5990462890625, \"max\": 5.5990462890625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6959813, \"EndTime\": 1648070451.6959994, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5034091796875, \"count\": 1, \"min\": 5.5034091796875, \"max\": 5.5034091796875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.6960478, \"EndTime\": 1648070451.6960642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.49375859375, \"count\": 1, \"min\": 5.49375859375, \"max\": 5.49375859375}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] #quality_metric: host=algo-1, epoch=1, validation absolute_loss_objective <loss>=0.8457241333007812\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=absolute_loss_objective, value=0.6742811401367188\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] Saved checkpoint to \"/tmp/tmp45kc12yx/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] #progress_metric: host=algo-1, completed 12.5 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070450.757621, \"EndTime\": 1648070451.707733, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 46996.0, \"count\": 1, \"min\": 46996, \"max\": 46996}, \"Total Batches Seen\": {\"sum\": 48.0, \"count\": 1, \"min\": 48, \"max\": 48}, \"Max Records Seen Between Resets\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Max Batches Seen Between Resets\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Number of Batches Since Last Reset\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:51 INFO 139682313451328] #throughput_metric: host=algo-1, train throughput=18412.943713420947 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5344307, \"EndTime\": 1648070452.5345242, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.06638977185417624, \"count\": 1, \"min\": 0.06638977185417624, \"max\": 0.06638977185417624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.534635, \"EndTime\": 1648070452.5346522, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.27402876730526193, \"count\": 1, \"min\": 0.27402876730526193, \"max\": 0.27402876730526193}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5347152, \"EndTime\": 1648070452.5347304, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.31069405050838694, \"count\": 1, \"min\": 0.31069405050838694, \"max\": 0.31069405050838694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5347855, \"EndTime\": 1648070452.534804, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.24920083797679227, \"count\": 1, \"min\": 0.24920083797679227, \"max\": 0.24920083797679227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.534858, \"EndTime\": 1648070452.5348747, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.061439568687887754, \"count\": 1, \"min\": 0.061439568687887754, \"max\": 0.061439568687887754}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5349302, \"EndTime\": 1648070452.5349486, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.08339708732156192, \"count\": 1, \"min\": 0.08339708732156192, \"max\": 0.08339708732156192}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5349998, \"EndTime\": 1648070452.5350199, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.05517498465145335, \"count\": 1, \"min\": 0.05517498465145335, \"max\": 0.05517498465145335}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5350733, \"EndTime\": 1648070452.5350916, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.07639901239731732, \"count\": 1, \"min\": 0.07639901239731732, \"max\": 0.07639901239731732}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5351455, \"EndTime\": 1648070452.5351603, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.307764747170841, \"count\": 1, \"min\": 0.307764747170841, \"max\": 0.307764747170841}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5352132, \"EndTime\": 1648070452.53523, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3337815533806296, \"count\": 1, \"min\": 0.3337815533806296, \"max\": 0.3337815533806296}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5352812, \"EndTime\": 1648070452.5353003, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2415706625545726, \"count\": 1, \"min\": 0.2415706625545726, \"max\": 0.2415706625545726}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5353487, \"EndTime\": 1648070452.5353668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28601741297104777, \"count\": 1, \"min\": 0.28601741297104777, \"max\": 0.28601741297104777}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5354218, \"EndTime\": 1648070452.5354378, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.0711173075507669, \"count\": 1, \"min\": 0.0711173075507669, \"max\": 0.0711173075507669}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5354834, \"EndTime\": 1648070452.535503, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.07892969131469726, \"count\": 1, \"min\": 0.07892969131469726, \"max\": 0.07892969131469726}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5355527, \"EndTime\": 1648070452.5355718, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.08637335833381204, \"count\": 1, \"min\": 0.08637335833381204, \"max\": 0.08637335833381204}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5356188, \"EndTime\": 1648070452.5356383, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.08029043422025793, \"count\": 1, \"min\": 0.08029043422025793, \"max\": 0.08029043422025793}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5356889, \"EndTime\": 1648070452.535707, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3332387300379136, \"count\": 1, \"min\": 0.3332387300379136, \"max\": 0.3332387300379136}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.535763, \"EndTime\": 1648070452.5357761, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.3026786355411305, \"count\": 1, \"min\": 0.3026786355411305, \"max\": 0.3026786355411305}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5358315, \"EndTime\": 1648070452.5358465, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2755025939941406, \"count\": 1, \"min\": 0.2755025939941406, \"max\": 0.2755025939941406}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5359023, \"EndTime\": 1648070452.5359185, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.28049537568933824, \"count\": 1, \"min\": 0.28049537568933824, \"max\": 0.28049537568933824}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5359726, \"EndTime\": 1648070452.535989, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1339563679414637, \"count\": 1, \"min\": 0.1339563679414637, \"max\": 0.1339563679414637}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5360422, \"EndTime\": 1648070452.5360613, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13597667828728172, \"count\": 1, \"min\": 0.13597667828728172, \"max\": 0.13597667828728172}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5361087, \"EndTime\": 1648070452.5361288, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12860464163387522, \"count\": 1, \"min\": 0.12860464163387522, \"max\": 0.12860464163387522}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5361774, \"EndTime\": 1648070452.5361934, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1424602185417624, \"count\": 1, \"min\": 0.1424602185417624, \"max\": 0.1424602185417624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5362437, \"EndTime\": 1648070452.5362582, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5519907406077665, \"count\": 1, \"min\": 0.5519907406077665, \"max\": 0.5519907406077665}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5363064, \"EndTime\": 1648070452.5363266, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5536307157628676, \"count\": 1, \"min\": 0.5536307157628676, \"max\": 0.5536307157628676}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5363753, \"EndTime\": 1648070452.5364258, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.553936092601103, \"count\": 1, \"min\": 0.553936092601103, \"max\": 0.553936092601103}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5364857, \"EndTime\": 1648070452.5364993, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5495149213005515, \"count\": 1, \"min\": 0.5495149213005515, \"max\": 0.5495149213005515}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5365548, \"EndTime\": 1648070452.5365734, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5566332756491268, \"count\": 1, \"min\": 0.5566332756491268, \"max\": 0.5566332756491268}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5366254, \"EndTime\": 1648070452.5366437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5536139131433824, \"count\": 1, \"min\": 0.5536139131433824, \"max\": 0.5536139131433824}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.5366943, \"EndTime\": 1648070452.536712, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5535672858743107, \"count\": 1, \"min\": 0.5535672858743107, \"max\": 0.5535672858743107}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.536788, \"EndTime\": 1648070452.5368063, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5547154181985294, \"count\": 1, \"min\": 0.5547154181985294, \"max\": 0.5547154181985294}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] #quality_metric: host=algo-1, epoch=2, train absolute_loss_objective <loss>=0.06638977185417624\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7506366, \"EndTime\": 1648070452.7507727, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.2484336669921876, \"count\": 1, \"min\": 1.2484336669921876, \"max\": 1.2484336669921876}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7509246, \"EndTime\": 1648070452.7509503, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.4676431640625, \"count\": 1, \"min\": 2.4676431640625, \"max\": 2.4676431640625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.751021, \"EndTime\": 1648070452.7510424, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.82099990234375, \"count\": 1, \"min\": 2.82099990234375, \"max\": 2.82099990234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.751099, \"EndTime\": 1648070452.7511153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.233633203125, \"count\": 1, \"min\": 2.233633203125, \"max\": 2.233633203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7511673, \"EndTime\": 1648070452.7511854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.5012408386230469, \"count\": 1, \"min\": 0.5012408386230469, \"max\": 0.5012408386230469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7512443, \"EndTime\": 1648070452.751262, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.155798828125, \"count\": 1, \"min\": 1.155798828125, \"max\": 1.155798828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7513146, \"EndTime\": 1648070452.7513323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.7123684326171875, \"count\": 1, \"min\": 0.7123684326171875, \"max\": 0.7123684326171875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7513876, \"EndTime\": 1648070452.7514012, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.882204736328125, \"count\": 1, \"min\": 1.882204736328125, \"max\": 1.882204736328125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7514572, \"EndTime\": 1648070452.7514746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.820050927734375, \"count\": 1, \"min\": 2.820050927734375, \"max\": 2.820050927734375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7515302, \"EndTime\": 1648070452.7515504, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.0226798828125, \"count\": 1, \"min\": 3.0226798828125, \"max\": 3.0226798828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7515974, \"EndTime\": 1648070452.7516153, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.1766214599609377, \"count\": 1, \"min\": 2.1766214599609377, \"max\": 2.1766214599609377}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7516658, \"EndTime\": 1648070452.7516828, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.599691552734375, \"count\": 1, \"min\": 2.599691552734375, \"max\": 2.599691552734375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.751732, \"EndTime\": 1648070452.7517457, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.595556884765625, \"count\": 1, \"min\": 0.595556884765625, \"max\": 0.595556884765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7517955, \"EndTime\": 1648070452.7518115, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.6279733154296875, \"count\": 1, \"min\": 0.6279733154296875, \"max\": 0.6279733154296875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.752045, \"EndTime\": 1648070452.752072, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.879441357421875, \"count\": 1, \"min\": 0.879441357421875, \"max\": 0.879441357421875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7521396, \"EndTime\": 1648070452.7521608, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.688953759765625, \"count\": 1, \"min\": 0.688953759765625, \"max\": 0.688953759765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7522202, \"EndTime\": 1648070452.7522407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 3.012805078125, \"count\": 1, \"min\": 3.012805078125, \"max\": 3.012805078125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.752309, \"EndTime\": 1648070452.752322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.724896923828125, \"count\": 1, \"min\": 2.724896923828125, \"max\": 2.724896923828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.752381, \"EndTime\": 1648070452.7524045, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.47720400390625, \"count\": 1, \"min\": 2.47720400390625, \"max\": 2.47720400390625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7524705, \"EndTime\": 1648070452.7524867, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.523497021484375, \"count\": 1, \"min\": 2.523497021484375, \"max\": 2.523497021484375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.75255, \"EndTime\": 1648070452.752566, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.404729541015625, \"count\": 1, \"min\": 1.404729541015625, \"max\": 1.404729541015625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7526202, \"EndTime\": 1648070452.7526355, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.241302734375, \"count\": 1, \"min\": 1.241302734375, \"max\": 1.241302734375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.752688, \"EndTime\": 1648070452.752705, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.1417757934570312, \"count\": 1, \"min\": 1.1417757934570312, \"max\": 1.1417757934570312}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7527838, \"EndTime\": 1648070452.7528038, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.3439627197265624, \"count\": 1, \"min\": 1.3439627197265624, \"max\": 1.3439627197265624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.752877, \"EndTime\": 1648070452.7528932, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5563146484375, \"count\": 1, \"min\": 5.5563146484375, \"max\": 5.5563146484375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7529402, \"EndTime\": 1648070452.7529562, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.57263876953125, \"count\": 1, \"min\": 5.57263876953125, \"max\": 5.57263876953125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7530103, \"EndTime\": 1648070452.7530274, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.564612109375, \"count\": 1, \"min\": 5.564612109375, \"max\": 5.564612109375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7531, \"EndTime\": 1648070452.75315, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5674208984375, \"count\": 1, \"min\": 5.5674208984375, \"max\": 5.5674208984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7532136, \"EndTime\": 1648070452.7532296, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5464943359375, \"count\": 1, \"min\": 5.5464943359375, \"max\": 5.5464943359375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7532873, \"EndTime\": 1648070452.7533047, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.58159990234375, \"count\": 1, \"min\": 5.58159990234375, \"max\": 5.58159990234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.7533565, \"EndTime\": 1648070452.753375, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.56011533203125, \"count\": 1, \"min\": 5.56011533203125, \"max\": 5.56011533203125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.75342, \"EndTime\": 1648070452.753436, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.6193755859375, \"count\": 1, \"min\": 5.6193755859375, \"max\": 5.6193755859375}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] #quality_metric: host=algo-1, epoch=2, validation absolute_loss_objective <loss>=1.2484336669921876\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=absolute_loss_objective, value=0.5012408386230469\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] Saved checkpoint to \"/tmp/tmp89u2btxk/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] #progress_metric: host=algo-1, completed 18.75 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070451.7080944, \"EndTime\": 1648070452.7664323, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 64494.0, \"count\": 1, \"min\": 64494, \"max\": 64494}, \"Total Batches Seen\": {\"sum\": 66.0, \"count\": 1, \"min\": 66, \"max\": 66}, \"Max Records Seen Between Resets\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Max Batches Seen Between Resets\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Number of Batches Since Last Reset\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:52 INFO 139682313451328] #throughput_metric: host=algo-1, train throughput=16530.44772301834 records/second\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4158719, \"EndTime\": 1648070453.41601, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.10899765306360581, \"count\": 1, \"min\": 0.10899765306360581, \"max\": 0.10899765306360581}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4161825, \"EndTime\": 1648070453.4162102, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.21316348266601562, \"count\": 1, \"min\": 0.21316348266601562, \"max\": 0.21316348266601562}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4166381, \"EndTime\": 1648070453.4166565, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.25072243095846736, \"count\": 1, \"min\": 0.25072243095846736, \"max\": 0.25072243095846736}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.416714, \"EndTime\": 1648070453.4167314, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.19083919480267694, \"count\": 1, \"min\": 0.19083919480267694, \"max\": 0.19083919480267694}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4167979, \"EndTime\": 1648070453.4168148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.049377120410694794, \"count\": 1, \"min\": 0.049377120410694794, \"max\": 0.049377120410694794}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4168694, \"EndTime\": 1648070453.4168863, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.07381570569206687, \"count\": 1, \"min\": 0.07381570569206687, \"max\": 0.07381570569206687}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.416945, \"EndTime\": 1648070453.4169562, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.06795999392341165, \"count\": 1, \"min\": 0.06795999392341165, \"max\": 0.06795999392341165}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4170058, \"EndTime\": 1648070453.4170232, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.15247786465813132, \"count\": 1, \"min\": 0.15247786465813132, \"max\": 0.15247786465813132}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4170864, \"EndTime\": 1648070453.4171033, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.2490208309397978, \"count\": 1, \"min\": 0.2490208309397978, \"max\": 0.2490208309397978}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.417165, \"EndTime\": 1648070453.417183, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.26916262278837316, \"count\": 1, \"min\": 0.26916262278837316, \"max\": 0.26916262278837316}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.417247, \"EndTime\": 1648070453.4172652, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.18533363073012407, \"count\": 1, \"min\": 0.18533363073012407, \"max\": 0.18533363073012407}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.417321, \"EndTime\": 1648070453.4173355, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22423204399557675, \"count\": 1, \"min\": 0.22423204399557675, \"max\": 0.22423204399557675}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4173882, \"EndTime\": 1648070453.4174054, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.09067258004581227, \"count\": 1, \"min\": 0.09067258004581227, \"max\": 0.09067258004581227}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4174595, \"EndTime\": 1648070453.417478, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.06251952070348403, \"count\": 1, \"min\": 0.06251952070348403, \"max\": 0.06251952070348403}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4175453, \"EndTime\": 1648070453.4175663, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.10055344682581284, \"count\": 1, \"min\": 0.10055344682581284, \"max\": 0.10055344682581284}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4176219, \"EndTime\": 1648070453.4176376, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.08350472102445715, \"count\": 1, \"min\": 0.08350472102445715, \"max\": 0.08350472102445715}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4176848, \"EndTime\": 1648070453.4177027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.27304605371811813, \"count\": 1, \"min\": 0.27304605371811813, \"max\": 0.27304605371811813}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4177542, \"EndTime\": 1648070453.4177713, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.24389575823615578, \"count\": 1, \"min\": 0.24389575823615578, \"max\": 0.24389575823615578}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4178255, \"EndTime\": 1648070453.4178429, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22149788172104778, \"count\": 1, \"min\": 0.22149788172104778, \"max\": 0.22149788172104778}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4178998, \"EndTime\": 1648070453.4179158, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.22596274701286764, \"count\": 1, \"min\": 0.22596274701286764, \"max\": 0.22596274701286764}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.41797, \"EndTime\": 1648070453.4179852, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.1205827870088465, \"count\": 1, \"min\": 0.1205827870088465, \"max\": 0.1205827870088465}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.418035, \"EndTime\": 1648070453.4180496, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.13042452643899358, \"count\": 1, \"min\": 0.13042452643899358, \"max\": 0.13042452643899358}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4181018, \"EndTime\": 1648070453.418117, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.12378413435992072, \"count\": 1, \"min\": 0.12378413435992072, \"max\": 0.12378413435992072}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.418168, \"EndTime\": 1648070453.4181862, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.11974148963479435, \"count\": 1, \"min\": 0.11974148963479435, \"max\": 0.11974148963479435}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4182363, \"EndTime\": 1648070453.4182515, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5522439216164982, \"count\": 1, \"min\": 0.5522439216164982, \"max\": 0.5522439216164982}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4183064, \"EndTime\": 1648070453.4183228, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5520102969898897, \"count\": 1, \"min\": 0.5520102969898897, \"max\": 0.5520102969898897}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4183793, \"EndTime\": 1648070453.4183943, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5517112319048714, \"count\": 1, \"min\": 0.5517112319048714, \"max\": 0.5517112319048714}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4184513, \"EndTime\": 1648070453.4184692, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5535113309972427, \"count\": 1, \"min\": 0.5535113309972427, \"max\": 0.5535113309972427}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4185195, \"EndTime\": 1648070453.418536, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5529108168658088, \"count\": 1, \"min\": 0.5529108168658088, \"max\": 0.5529108168658088}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4185886, \"EndTime\": 1648070453.4186056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5539023904239431, \"count\": 1, \"min\": 0.5539023904239431, \"max\": 0.5539023904239431}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4186597, \"EndTime\": 1648070453.4186754, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5538080408432905, \"count\": 1, \"min\": 0.5538080408432905, \"max\": 0.5538080408432905}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.4187326, \"EndTime\": 1648070453.4187481, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_absolute_loss_objective\": {\"sum\": 0.5537935252470129, \"count\": 1, \"min\": 0.5537935252470129, \"max\": 0.5537935252470129}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] #quality_metric: host=algo-1, epoch=3, train absolute_loss_objective <loss>=0.10899765306360581\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5730906, \"EndTime\": 1648070453.57321, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.7408075805664063, \"count\": 1, \"min\": 0.7408075805664063, \"max\": 0.7408075805664063}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5733695, \"EndTime\": 1648070453.573395, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.9043967529296875, \"count\": 1, \"min\": 1.9043967529296875, \"max\": 1.9043967529296875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.573475, \"EndTime\": 1648070453.5735002, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.272879931640625, \"count\": 1, \"min\": 2.272879931640625, \"max\": 2.272879931640625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.57358, \"EndTime\": 1648070453.5735993, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.6708952880859376, \"count\": 1, \"min\": 1.6708952880859376, \"max\": 1.6708952880859376}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5738106, \"EndTime\": 1648070453.5738328, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.5891940551757813, \"count\": 1, \"min\": 0.5891940551757813, \"max\": 0.5891940551757813}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.573889, \"EndTime\": 1648070453.5739043, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.3875408508300781, \"count\": 1, \"min\": 0.3875408508300781, \"max\": 0.3875408508300781}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5739553, \"EndTime\": 1648070453.5739715, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.9519273559570313, \"count\": 1, \"min\": 0.9519273559570313, \"max\": 0.9519273559570313}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5740244, \"EndTime\": 1648070453.5740416, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.707306591796875, \"count\": 1, \"min\": 1.707306591796875, \"max\": 1.707306591796875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5741105, \"EndTime\": 1648070453.5741289, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.2449153564453126, \"count\": 1, \"min\": 2.2449153564453126, \"max\": 2.2449153564453126}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5741856, \"EndTime\": 1648070453.5742023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.442758251953125, \"count\": 1, \"min\": 2.442758251953125, \"max\": 2.442758251953125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.574259, \"EndTime\": 1648070453.5742757, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.609098486328125, \"count\": 1, \"min\": 1.609098486328125, \"max\": 1.609098486328125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5743263, \"EndTime\": 1648070453.5743437, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.9760822998046874, \"count\": 1, \"min\": 1.9760822998046874, \"max\": 1.9760822998046874}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5743961, \"EndTime\": 1648070453.5744135, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.6409091796875, \"count\": 1, \"min\": 0.6409091796875, \"max\": 0.6409091796875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5744653, \"EndTime\": 1648070453.574482, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.6152512451171875, \"count\": 1, \"min\": 0.6152512451171875, \"max\": 0.6152512451171875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5745342, \"EndTime\": 1648070453.5745516, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.1116362548828125, \"count\": 1, \"min\": 1.1116362548828125, \"max\": 1.1116362548828125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5746047, \"EndTime\": 1648070453.5746195, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 0.87772119140625, \"count\": 1, \"min\": 0.87772119140625, \"max\": 0.87772119140625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.574667, \"EndTime\": 1648070453.574682, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.493249462890625, \"count\": 1, \"min\": 2.493249462890625, \"max\": 2.493249462890625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5747333, \"EndTime\": 1648070453.57475, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.1896291259765626, \"count\": 1, \"min\": 2.1896291259765626, \"max\": 2.1896291259765626}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5748034, \"EndTime\": 1648070453.5748208, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.9972560791015626, \"count\": 1, \"min\": 1.9972560791015626, \"max\": 1.9972560791015626}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5748763, \"EndTime\": 1648070453.574893, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 2.030113134765625, \"count\": 1, \"min\": 2.030113134765625, \"max\": 2.030113134765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5749438, \"EndTime\": 1648070453.5749593, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.302498095703125, \"count\": 1, \"min\": 1.302498095703125, \"max\": 1.302498095703125}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5750082, \"EndTime\": 1648070453.575023, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.3809199462890624, \"count\": 1, \"min\": 1.3809199462890624, \"max\": 1.3809199462890624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5750747, \"EndTime\": 1648070453.5750897, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.2733880859375, \"count\": 1, \"min\": 1.2733880859375, \"max\": 1.2733880859375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5751376, \"EndTime\": 1648070453.5751538, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 1.283225634765625, \"count\": 1, \"min\": 1.283225634765625, \"max\": 1.283225634765625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5752044, \"EndTime\": 1648070453.5752199, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.55823740234375, \"count\": 1, \"min\": 5.55823740234375, \"max\": 5.55823740234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5752754, \"EndTime\": 1648070453.575292, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.55382333984375, \"count\": 1, \"min\": 5.55382333984375, \"max\": 5.55382333984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5753438, \"EndTime\": 1648070453.5753608, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5647654296875, \"count\": 1, \"min\": 5.5647654296875, \"max\": 5.5647654296875}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5754132, \"EndTime\": 1648070453.575431, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.5578802734375, \"count\": 1, \"min\": 5.5578802734375, \"max\": 5.5578802734375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5754802, \"EndTime\": 1648070453.5754972, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.54656708984375, \"count\": 1, \"min\": 5.54656708984375, \"max\": 5.54656708984375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5755646, \"EndTime\": 1648070453.5755816, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.58221416015625, \"count\": 1, \"min\": 5.58221416015625, \"max\": 5.58221416015625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5756414, \"EndTime\": 1648070453.5756617, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.57232197265625, \"count\": 1, \"min\": 5.57232197265625, \"max\": 5.57232197265625}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070453.5757134, \"EndTime\": 1648070453.5757291, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"validation_absolute_loss_objective\": {\"sum\": 5.57136162109375, \"count\": 1, \"min\": 5.57136162109375, \"max\": 5.57136162109375}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] #quality_metric: host=algo-1, epoch=3, validation absolute_loss_objective <loss>=0.7408075805664063\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=absolute_loss_objective, value=0.3875408508300781\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] Saved checkpoint to \"/tmp/tmpukjdcqzi/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1648070452.766794, \"EndTime\": 1648070453.5871217, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 81992.0, \"count\": 1, \"min\": 81992, \"max\": 81992}, \"Total Batches Seen\": {\"sum\": 84.0, \"count\": 1, \"min\": 84, \"max\": 84}, \"Max Records Seen Between Resets\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Max Batches Seen Between Resets\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 17498.0, \"count\": 1, \"min\": 17498, \"max\": 17498}, \"Number of Batches Since Last Reset\": {\"sum\": 18.0, \"count\": 1, \"min\": 18, \"max\": 18}}}\u001b[0m\n",
      "\u001b[34m[03/23/2022 21:20:53 INFO 139682313451328] #throughput_metric: host=algo-1, train throughput=21324.79648909933 records/second\u001b[0m\n",
      "\n",
      "2022-03-23 21:21:12 Uploading - Uploading generated training model"
     ]
    }
   ],
   "source": [
    "# cell 16\n",
    "# %%time\n",
    "linear.fit(inputs={\"train\": train_data, \"validation\": validation_data}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "\n",
    "Once the training is done, we can deploy the trained model as an Amazon SageMaker real-time hosted endpoint. This will allow us to make predictions (or inference) from the model. Note that we don't have to host on the same insantance (or type of instance) that we used to train. Training is a prolonged and compute heavy job that require a different of compute and memory requirements that hosting typically do not. We can choose any type of instance we want to host the model. In our case we chose the ml.m4.xlarge instance to train, but we choose to host the model on the less expensive cpu instance, ml.c4.xlarge. The endpoint deployment can be accomplished as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 17\n",
    "# %%time\n",
    "# creating the endpoint out of the trained model\n",
    "linear_predictor = linear.deploy(initial_instance_count=1, instance_type=\"ml.c4.xlarge\")\n",
    "print(f\"\\ncreated endpoint: {linear_predictor.endpoint_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy the endpoint name of the deployed model from above and save it for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Now that the trained model is deployed at an endpoint that is up-and-running, we can use this endpoint for inference. To do this, we are going to configure the [predictor object](https://sagemaker.readthedocs.io/en/v1.2.4/predictors.html) to parse contents of type text/csv and deserialize the reply received from the endpoint to json format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 18\n",
    "# configure the predictor to accept to serialize csv input and parse the reposne as json\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "linear_predictor.serializer = CSVSerializer()\n",
    "linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We then use the test file containing the records of the data that we kept to test the model prediction. By running below cell multiple times we are selecting random sample from the testing samples to perform inference with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 19\n",
    "# %%time\n",
    "import json\n",
    "from itertools import islice\n",
    "import math\n",
    "import struct\n",
    "import boto3\n",
    "import random\n",
    "\n",
    "# downloading the test file from data_bucket\n",
    "FILE_TEST = \"test.csv\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(data_bucket, f\"{data_prefix}/test/{FILE_TEST}\", FILE_TEST)\n",
    "\n",
    "# getting testing sample from our test file\n",
    "test_data = [l for l in open(FILE_TEST, \"r\")]\n",
    "sample = random.choice(test_data).split(\",\")\n",
    "actual_fare = sample[0]\n",
    "payload = sample[1:]  # removing actual age from the sample\n",
    "payload = \",\".join(map(str, payload))\n",
    "print('payload: ', payload, type(payload))\n",
    "# Invoke the predicor and analyise the result\n",
    "result = linear_predictor.predict(payload)\n",
    "print('Result:', result)\n",
    "# extracting the prediction value\n",
    "result = round(float(result[\"predictions\"][0][\"score\"]), 2)\n",
    "\n",
    "\n",
    "accuracy = str(round(100 - ((abs(float(result) - float(actual_fare)) / float(actual_fare)) * 100), 2))\n",
    "print(f\"Actual fare: {actual_fare}\\nPrediction: {result}\\nAccuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 20\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
